{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnNames(object):\n",
    "    \"\"\"\n",
    "    Column names\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, user_col, item_col, rating_col):\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "        self.rating_col = rating_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NcfTrainingArguments(object):\n",
    "    def __init__(self, user_dim, item_dim, batch_size, num_epochs, hidden1_dim,\n",
    "                 hidden2_dim):\n",
    "        self.user_dim = user_dim\n",
    "        self.item_dim = item_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "\n",
    "\n",
    "config = {\n",
    "    'training_args':\n",
    "    NcfTrainingArguments(\n",
    "        user_dim=10,\n",
    "        item_dim=6,\n",
    "        batch_size=16,\n",
    "        num_epochs=5,\n",
    "        hidden1_dim=8,\n",
    "        hidden2_dim=2),\n",
    "    'col_names':\n",
    "    ColumnNames(user_col='user', item_col='item', rating_col='rating')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(object):\n",
    "    \"\"\"\n",
    "    This class implements matrix factorization using the tf2 api\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_users, n_items, user_dim, item_dim):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.user_dim = user_dim\n",
    "        self.item_dim = item_dim\n",
    "        self.input_user, self.input_item, self.input_rating, self.user_embeddings, self.item_embeddings =\\\n",
    "            self.inputs_weights_init()\n",
    "\n",
    "    @staticmethod\n",
    "    def inputs_init():\n",
    "        \"\"\"\n",
    "        Initialises the necessary inputs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_user = tf.keras.Input((1, ))\n",
    "        input_item = tf.keras.Input((1, ))\n",
    "        input_rating = tf.keras.Input((1, ))\n",
    "        return input_user, input_item, input_rating\n",
    "\n",
    "    def embeddings_layers_init(self):\n",
    "        \"\"\"\n",
    "        Initialises the embeddings layers\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        user_embeddings = tf.keras.layers.Embedding(\n",
    "            self.n_users, self.user_dim, input_length=1)\n",
    "\n",
    "        item_embeddings = tf.keras.layers.Embedding(\n",
    "            self.n_items, self.item_dim, input_length=1)\n",
    "\n",
    "        return user_embeddings, item_embeddings\n",
    "\n",
    "    def inputs_weights_init(self):\n",
    "        \"\"\"\n",
    "        Initialises inputs and weights\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_user, input_item, input_rating = self.inputs_init()\n",
    "        user_embeddings, item_embeddings = self.embeddings_layers_init()\n",
    "\n",
    "        return input_user, input_item, input_rating, user_embeddings, item_embeddings\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Generate predictions by defining the architecture\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_item_vector = self.item_embeddings(self.input_item)\n",
    "        input_user_vector = self.user_embeddings(self.input_user)\n",
    "        input_item_vector_reshaped = tf.keras.layers.Reshape(\n",
    "            (self.item_dim, 1))(input_item_vector)\n",
    "        input_user_vector_reshaped = tf.keras.layers.Reshape(\n",
    "            (self.user_dim, 1))(input_user_vector)\n",
    "\n",
    "        dot_product = tf.keras.layers.dot(\n",
    "            [input_item_vector_reshaped, input_user_vector_reshaped], axes=2)\n",
    "        predicted_rating = tf.keras.layers.Dense(\n",
    "            1, activation='linear')(dot_product)\n",
    "        return predicted_rating\n",
    "\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        Define the keras model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        model = tf.keras.Model(\n",
    "            inputs=[self.input_user, self.input_item], outputs=self.predict())\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCF(object):\n",
    "    \"\"\"\n",
    "    This class implements matrix factorization using the tf2 api\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_users, n_items, user_dim, item_dim, hidden1_dim,\n",
    "                 hidden2_dim):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.user_dim = user_dim\n",
    "        self.item_dim = item_dim\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "        self.input_user, self.input_item, self.input_rating, self.user_embeddings, self.item_embeddings =\\\n",
    "            self.inputs_weights_init()\n",
    "\n",
    "    @staticmethod\n",
    "    def inputs_init():\n",
    "        \"\"\"\n",
    "        Initialises the necessary inputs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_user = tf.keras.Input((1, ))\n",
    "        input_item = tf.keras.Input((1, ))\n",
    "        input_rating = tf.keras.Input((1, ))\n",
    "        return input_user, input_item, input_rating\n",
    "\n",
    "    def embeddings_layers_init(self):\n",
    "        \"\"\"\n",
    "        Initialises the embeddings layers\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        user_embeddings = tf.keras.layers.Embedding(\n",
    "            self.n_users, self.user_dim, input_length=1)\n",
    "\n",
    "        item_embeddings = tf.keras.layers.Embedding(\n",
    "            self.n_items, self.item_dim, input_length=1)\n",
    "\n",
    "        return user_embeddings, item_embeddings\n",
    "\n",
    "    def inputs_weights_init(self):\n",
    "        \"\"\"\n",
    "        Initialises inputs and weights\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_user, input_item, input_rating = self.inputs_init()\n",
    "        user_embeddings, item_embeddings = self.embeddings_layers_init()\n",
    "\n",
    "        return input_user, input_item, input_rating, user_embeddings, item_embeddings\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Generate predictions by defining the architecture\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_item_vector = self.item_embeddings(self.input_item)\n",
    "        input_user_vector = self.user_embeddings(self.input_user)\n",
    "        input_item_vector_reshaped = tf.keras.layers.Reshape(\n",
    "            (self.item_dim, 1))(input_item_vector)\n",
    "        input_user_vector_reshaped = tf.keras.layers.Reshape(\n",
    "            (self.user_dim, 1))(input_user_vector)\n",
    "\n",
    "        # concatenation of user and item embeddings\n",
    "        user_item_vector_concat = tf.keras.layers.concatenate(\n",
    "            [input_item_vector_reshaped, input_user_vector_reshaped], axis=1)\n",
    "\n",
    "        # first dense layer\n",
    "        dense1 = tf.keras.layers.Dense(\n",
    "            self.hidden1_dim)(user_item_vector_concat)\n",
    "        dropout_1 = tf.keras.layers.Dropout(0.1)(dense1)\n",
    "        # second dense layer\n",
    "        dense2 = tf.keras.layers.Dense(self.hidden2_dim)(dropout_1)\n",
    "        predicted_rating = tf.keras.layers.Dense(\n",
    "            1, activation='linear')(dense2)\n",
    "        return predicted_rating\n",
    "\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        Define the keras model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        model = tf.keras.Model(\n",
    "            inputs=[self.input_user, self.input_item], outputs=self.predict())\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnIndexer(object):\n",
    "    \"\"\"\n",
    "    This class in used in order to index\n",
    "    columns like user id, item id in a pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, col_names):\n",
    "        self.df = df\n",
    "        self.col_names = col_names\n",
    "        self.distinct_items = self.get_distinct_items()\n",
    "        self.indexers, self.reverse_indexers = self.generate_indexers()\n",
    "\n",
    "    def get_distinct_items(self):\n",
    "        \"\"\"\n",
    "        Get all the distinct item in the column\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        distinct_items = {\n",
    "            col_name: set(self.df[col_name].values)\n",
    "            for col_name in self.col_names\n",
    "        }\n",
    "        return distinct_items\n",
    "\n",
    "    def generate_indexers(self):\n",
    "        \"\"\"\n",
    "        Builds the indexers and the reverse indexers for all\n",
    "        the columns defined when instantiating the class\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        indexers = {\n",
    "            col: {k: v\n",
    "                  for v, k in enumerate(distinct_item)}\n",
    "            for col, distinct_item in self.distinct_items.items()\n",
    "        }\n",
    "        reverse_indexers = {\n",
    "            col: {v: k\n",
    "                  for k, v in indexer.items()}\n",
    "            for col, indexer in indexers.items()\n",
    "        }\n",
    "        return indexers, reverse_indexers\n",
    "\n",
    "    def transform(self, dataset):\n",
    "        \"\"\"                                                                     \n",
    "        Transforms the original dataset\n",
    "        by adding indexed versions of the columns\n",
    "        :param dataset: Original pandas dataframe\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for col in self.col_names:\n",
    "            dataset[col + '_indexed'] = dataset[col]\\\n",
    "                .map(self.indexers[col])\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSimilarityCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfTrainingArguments(object):\n",
    "    \"\"\"\n",
    "    Training arguments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, user_dim, item_dim, batch_size, num_epochs):\n",
    "        self.user_dim = user_dim\n",
    "        self.item_dim = item_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "\n",
    "config = {\n",
    "    'training_args':\n",
    "    MfTrainingArguments(user_dim=10, item_dim=5, batch_size=16, num_epochs=5),\n",
    "    'col_names':                                               \n",
    "    ColumnNames(user_col='user', item_col='item', rating_col='r                       ting')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    training_args = config['training_args']\n",
    "    col_names = config['col_names']                                                                                                                     \n",
    "\n",
    "    # read in the train set\n",
    "    train = pd.read_csv(                                                                                        \n",
    "        'tf2recommender/data/u1_base.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])\n",
    "\n",
    "    # read in the test set\n",
    "    test = pd.read_csv(\n",
    "        'tf2recommender/data/u1_test.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])\n",
    "\n",
    "    # drop users and items that do not exist in the training set\n",
    "    test = test[test['item'].isin(train['item'].values)]\n",
    "\n",
    "    # instantiate the column index for both user and items\n",
    "    indexer = ColumnIndexer(train, ['user', 'item'])\n",
    "\n",
    "    # index the train set\n",
    "    train = indexer.transform(train)\n",
    "    # index the test set\n",
    "    test = indexer.transform(test)\n",
    "\n",
    "    # get the number of distinct users and items\n",
    "    number_of_users = len(set(train[col_names.user_col].values))\n",
    "    number_of_items = len(set(train[col_names.item_col].values))\n",
    "\n",
    "    # create user item rating tuples\n",
    "    train_users_items_ratings = ((\n",
    "        train[col_names.user_col + '_indexed'].values,\n",
    "        train[col_names.item_col + '_indexed'].values),\n",
    "                                 train[col_names.rating_col].values)\n",
    "\n",
    "    test_users_items_ratings = ((test[col_names.user_col + '_indexed'].values,\n",
    "                                 test[col_names.item_col + '_indexed'].values),\n",
    "                                test[col_names.rating_col].values)\n",
    "\n",
    "    # instantiate the tf datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        train_users_items_ratings)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test_users_items_ratings)\n",
    "\n",
    "    train_batches = train_dataset.shuffle(1000).batch(training_args.batch_size).prefetch(1)\n",
    "    test_batches = test_dataset.batch(training_args.batch_size).prefetch(1)\n",
    "\n",
    "    mf = MatrixFactorization(number_of_users, number_of_items,\n",
    "                             training_args.user_dim, training_args.item_dim)\n",
    "\n",
    "    model = mf.model()\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "    model.fit(train_batches, epochs=training_args.num_epochs)\n",
    "\n",
    "    print('\\n# Evaluate')\n",
    "    print(model.evaluate(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NcfTrainingArguments(object):\n",
    "    def __init__(self, user_dim, item_dim, batch_size, num_epochs, hidden1_dim,\n",
    "                 hidden2_dim):\n",
    "        self.user_dim = user_dim\n",
    "        self.item_dim = item_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "\n",
    "\n",
    "config = {\n",
    "    'training_args':\n",
    "    NcfTrainingArguments(\n",
    "        user_dim=10,\n",
    "        item_dim=6,\n",
    "        batch_size=16,\n",
    "        num_epochs=5,\n",
    "        hidden1_dim=8,\n",
    "        hidden2_dim=2),\n",
    "    'col_names':\n",
    "    ColumnNames(user_col='user', item_col='item', rating_col='rating')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = config['training_args']\n",
    "col_names = config['col_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    training_args = config['training_args']\n",
    "    col_names = config['col_names']\n",
    "\n",
    "    # read in the train set\n",
    "    train = pd.read_csv(\n",
    "        'tf2recommender/data/u1_base.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])\n",
    "\n",
    "    # read in the test set\n",
    "    test = pd.read_csv(\n",
    "        'tf2recommender/data/u1_test.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])\n",
    "\n",
    "    # drop users and items that do not exist in the training set\n",
    "    test = test[test['item'].isin(train['item'].values)]\n",
    "\n",
    "    # instantiate the column index for both user and items\n",
    "    indexer = ColumnIndexer(train, ['user', 'item'])\n",
    "\n",
    "    # index the train set\n",
    "    train = indexer.transform(train)\n",
    "    # index the test set\n",
    "    test = indexer.transform(test)\n",
    "\n",
    "    # get the number of distinct users and items\n",
    "    number_of_users = len(set(train[col_names.user_col].values))\n",
    "    number_of_items = len(set(train[col_names.item_col].values))\n",
    "\n",
    "    # create user item rating tuples\n",
    "    train_users_items_ratings = ((\n",
    "        train[col_names.user_col + '_indexed'].values,\n",
    "        train[col_names.item_col + '_indexed'].values),\n",
    "                                 train[col_names.rating_col].values)\n",
    "\n",
    "    test_users_items_ratings = ((test[col_names.user_col + '_indexed'].values,\n",
    "                                 test[col_names.item_col + '_indexed'].values),\n",
    "                                test[col_names.rating_col].values)\n",
    "\n",
    "    # instantiate the tf datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        train_users_items_ratings)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test_users_items_ratings)\n",
    "\n",
    "    train_batches = train_dataset.shuffle(1000).batch(training_args.batch_size).prefetch(1)\n",
    "    test_batches = test_dataset.batch(training_args.batch_size).prefetch(1)\n",
    "\n",
    "    ncf = NeuralCF(number_of_users, number_of_items, training_args.user_dim,\n",
    "                   training_args.item_dim, training_args.hidden1_dim,\n",
    "                   training_args.hidden2_dim)\n",
    "\n",
    "    model = ncf.model()\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "    model.fit(train_batches, epochs=training_args.num_epochs)\n",
    "\n",
    "    print('\\n# Evaluate')\n",
    "    print(model.evaluate(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = config['col_names']\n",
    "col_names = config['col_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "        'data/u1_base.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1     1       5\n",
       "1     1     2       3\n",
       "2     1     3       4\n",
       "3     1     4       3\n",
       "4     1     5       3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "        'data/u1_test.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop users and items that do not exist in the training set\n",
    "test = test[test['item'].isin(train['item'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1     6       5\n",
       "1     1    10       3\n",
       "2     1    12       5\n",
       "3     1    14       5\n",
       "4     1    17       3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the column index for both user and items\n",
    "indexer = ColumnIndexer(train, ['user', 'item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the train set\n",
    "train = indexer.transform(train)\n",
    "# index the test set\n",
    "test = indexer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_indexed</th>\n",
       "      <th>item_indexed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  user_indexed  item_indexed\n",
       "0     1     1       5             0             0\n",
       "1     1     2       3             0             1\n",
       "2     1     3       4             0             2\n",
       "3     1     4       3             0             3\n",
       "4     1     5       3             0             4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_indexed</th>\n",
       "      <th>item_indexed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  user_indexed  item_indexed\n",
       "0     1     6       5             0             5\n",
       "1     1    10       3             0             9\n",
       "2     1    12       5             0            11\n",
       "3     1    14       5             0            13\n",
       "4     1    17       3             0            16"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of distinct users and items\n",
    "number_of_users = len(set(train[col_names.user_col].values))\n",
    "number_of_items = len(set(train[col_names.item_col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1650\n"
     ]
    }
   ],
   "source": [
    "print(number_of_users)\n",
    "print(number_of_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user item rating tuples\n",
    "train_users_items_ratings = ((\n",
    "        train[col_names.user_col + '_indexed'].values,\n",
    "        train[col_names.item_col + '_indexed'].values),\n",
    "                                 train[col_names.rating_col].values)\n",
    "\n",
    "test_users_items_ratings = ((test[col_names.user_col + '_indexed'].values,\n",
    "                                 test[col_names.item_col + '_indexed'].values),\n",
    "                                test[col_names.rating_col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([  0,   0,   0, ..., 942, 942, 942]), array([   0,    1,    2, ..., 1180, 1220, 1318])), array([5, 3, 4, ..., 3, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "print(train_users_items_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([  0,   0,   0, ..., 458, 459, 461]), array([  5,   9,  11, ..., 927,   9, 680])), array([5, 3, 5, ..., 3, 3, 5]))\n"
     ]
    }
   ],
   "source": [
    "print(test_users_items_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 6)         9900        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 10)        9430        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 6, 1)         0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 1)        0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 1)        0           reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16, 8)        16          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 8)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16, 2)        18          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16, 1)        3           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,367\n",
      "Trainable params: 19,367\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train for 5000 steps\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 1.4509 - mse: 1.4509\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 1.0889 - mse: 1.0889\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 1.0624 - mse: 1.0624\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 1.0547 - mse: 1.0547\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 1.0509 - mse: 1.0509\n",
      "\n",
      "# Evaluate\n",
      "1248/1248 [==============================] - 1s 773us/step - loss: 1.1099 - mse: 1.1099\n",
      "[1.1098877313451316, 1.1098876]\n"
     ]
    }
   ],
   "source": [
    "# instantiate the tf datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        train_users_items_ratings)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_users_items_ratings)\n",
    "\n",
    "train_batches = train_dataset.shuffle(1000).batch(training_args.batch_size).prefetch(1)\n",
    "test_batches = test_dataset.batch(training_args.batch_size).prefetch(1)\n",
    "\n",
    "ncf = NeuralCF(number_of_users, number_of_items, training_args.user_dim,\n",
    "                   training_args.item_dim, training_args.hidden1_dim,\n",
    "                   training_args.hidden2_dim)\n",
    "model = ncf.model()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "model.fit(train_batches, epochs=training_args.num_epochs)\n",
    "\n",
    "print('\\n# Evaluate')\n",
    "print(model.evaluate(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCF(object):\n",
    "    \"\"\"\n",
    "    This class implements matrix factorization using the tf2 api\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_users, n_items, user_dim, item_dim, hidden1_dim,\n",
    "                 hidden2_dim):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.user_dim = user_dim\n",
    "        self.item_dim = item_dim\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "        self.input_user, self.input_item, self.input_rating, self.user_embeddings, self.item_embeddings =\\\n",
    "            self.inputs_weights_init()\n",
    "\n",
    "    @staticmethod\n",
    "    def inputs_init():\n",
    "        \"\"\"\n",
    "        Initialises the necessary inputs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_user = tf.keras.Input((1, ))\n",
    "        input_item = tf.keras.Input((1, ))\n",
    "        input_rating = tf.keras.Input((1, ))\n",
    "        return input_user, input_item, input_rating\n",
    "\n",
    "    def embeddings_layers_init(self):\n",
    "        \"\"\"\n",
    "        Initialises the embeddings layers\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        user_embeddings = tf.keras.layers.Embedding(\n",
    "            self.n_users, self.user_dim, input_length=1)\n",
    "\n",
    "        item_embeddings = tf.keras.layers.Embedding(\n",
    "            self.n_items, self.item_dim, input_length=1)\n",
    "\n",
    "        return user_embeddings, item_embeddings\n",
    "\n",
    "    def inputs_weights_init(self):\n",
    "        \"\"\"\n",
    "        Initialises inputs and weights\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_user, input_item, input_rating = self.inputs_init()\n",
    "        user_embeddings, item_embeddings = self.embeddings_layers_init()\n",
    "\n",
    "        return input_user, input_item, input_rating, user_embeddings, item_embeddings\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Generate predictions by defining the architecture\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        input_item_vector = self.item_embeddings(self.input_item)\n",
    "        input_user_vector = self.user_embeddings(self.input_user)\n",
    "        input_item_vector_reshaped = tf.keras.layers.Reshape(\n",
    "            (self.item_dim, 1))(input_item_vector)\n",
    "        input_user_vector_reshaped = tf.keras.layers.Reshape(\n",
    "            (self.user_dim, 1))(input_user_vector)\n",
    "\n",
    "        # concatenation of user and item embeddings\n",
    "        user_item_vector_concat = tf.keras.layers.concatenate(\n",
    "            [input_item_vector_reshaped, input_user_vector_reshaped], axis=1)\n",
    "\n",
    "        # first dense layer\n",
    "        dense1 = tf.keras.layers.Dense(\n",
    "            self.hidden1_dim)(user_item_vector_concat)\n",
    "        dropout_1 = tf.keras.layers.Dropout(0.1)(dense1)\n",
    "        # second dense layer\n",
    "        dense2 = tf.keras.layers.Dense(self.hidden2_dim)(dropout_1)\n",
    "        predicted_rating = tf.keras.layers.Dense(\n",
    "            1, activation='linear')(dense2)\n",
    "        return predicted_rating\n",
    "\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        Define the keras model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        model = tf.keras.Model(\n",
    "            inputs=[self.input_user, self.input_item], outputs=self.predict())\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    training_args = config['training_args']\n",
    "    col_names = config['col_names']\n",
    "\n",
    "    # read in the train set\n",
    "    train = pd.read_csv(\n",
    "        'tf2recommender/data/u1_base.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])\n",
    "\n",
    "    # read in the test set\n",
    "    test = pd.read_csv(\n",
    "        'tf2recommender/data/u1_test.csv',\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[col_names.user_col, col_names.item_col, col_names.rating_col])\n",
    "\n",
    "    # drop users and items that do not exist in the training set\n",
    "    test = test[test['item'].isin(train['item'].values)]\n",
    "\n",
    "    # instantiate the column index for both user and items\n",
    "    indexer = ColumnIndexer(train, ['user', 'item'])\n",
    "\n",
    "    # index the train set\n",
    "    train = indexer.transform(train)\n",
    "    # index the test set\n",
    "    test = indexer.transform(test)\n",
    "\n",
    "    # get the number of distinct users and items\n",
    "    number_of_users = len(set(train[col_names.user_col].values))\n",
    "    number_of_items = len(set(train[col_names.item_col].values))\n",
    "\n",
    "    # create user item rating tuples\n",
    "    train_users_items_ratings = ((\n",
    "        train[col_names.user_col + '_indexed'].values,\n",
    "        train[col_names.item_col + '_indexed'].values),\n",
    "                                 train[col_names.rating_col].values)\n",
    "\n",
    "    test_users_items_ratings = ((test[col_names.user_col + '_indexed'].values,\n",
    "                                 test[col_names.item_col + '_indexed'].values),\n",
    "                                test[col_names.rating_col].values)\n",
    "\n",
    "    # instantiate the tf datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        train_users_items_ratings)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test_users_items_ratings)\n",
    "\n",
    "    train_batches = train_dataset.shuffle(1000).batch(training_args.batch_size).prefetch(1)\n",
    "    test_batches = test_dataset.batch(training_args.batch_size).prefetch(1)\n",
    "\n",
    "    mf = MatrixFactorization(number_of_users, number_of_items,\n",
    "                             training_args.user_dim, training_args.item_dim)\n",
    "\n",
    "    model = mf.model()\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "    model.fit(train_batches, epochs=training_args.num_epochs)\n",
    "\n",
    "    print('\\n# Evaluate')\n",
    "    print(model.evaluate(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 6)         9900        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 10)        9430        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 6, 1)         0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 1)        0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 6, 10)        0           reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 6, 1)         11          dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 19,341\n",
      "Trainable params: 19,341\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train for 5000 steps\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 3.7108 - mse: 3.7108\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9795 - mse: 0.9795\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.9179 - mse: 0.9179\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9093 - mse: 0.9093\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.9051 - mse: 0.9051\n",
      "\n",
      "# Evaluate\n",
      "1248/1248 [==============================] - 1s 553us/step - loss: 0.9610 - mse: 0.9610\n",
      "[0.9609890046577232, 0.96098924]\n"
     ]
    }
   ],
   "source": [
    "# get the number of distinct users and items\n",
    "number_of_users = len(set(train[col_names.user_col].values))\n",
    "number_of_items = len(set(train[col_names.item_col].values))\n",
    "\n",
    "    # create user item rating tuples\n",
    "train_users_items_ratings = ((\n",
    "        train[col_names.user_col + '_indexed'].values,\n",
    "        train[col_names.item_col + '_indexed'].values),\n",
    "                                 train[col_names.rating_col].values)\n",
    "\n",
    "test_users_items_ratings = ((test[col_names.user_col + '_indexed'].values,\n",
    "                                 test[col_names.item_col + '_indexed'].values),\n",
    "                                test[col_names.rating_col].values)\n",
    "\n",
    "    # instantiate the tf datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        train_users_items_ratings)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_users_items_ratings)\n",
    "\n",
    "train_batches = train_dataset.shuffle(1000).batch(training_args.batch_size).prefetch(1)\n",
    "test_batches = test_dataset.batch(training_args.batch_size).prefetch(1)\n",
    "\n",
    "mf = MatrixFactorization(number_of_users, number_of_items,\n",
    "                             training_args.user_dim, training_args.item_dim)\n",
    "\n",
    "model = mf.model()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "model.fit(train_batches, epochs=training_args.num_epochs)\n",
    "\n",
    "print('\\n# Evaluate')\n",
    "print(model.evaluate(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Embedding, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel(Sequential):\n",
    "\n",
    "    # The constructor for the class\n",
    "    def __init__(self, n_users, m_items, k_factors, **kwargs):\n",
    "        # P is the embedding layer that creates an User by latent factors matrix.\n",
    "        # If the intput is a user_id, P returns the latent factor vector for that user.\n",
    "        P = Sequential()\n",
    "        P.add(Embedding(n_users, k_factors, input_length=1))\n",
    "        P.add(Reshape((k_factors,)))\n",
    "\n",
    "        # Q is the embedding layer that creates a Movie by latent factors matrix.\n",
    "        # If the input is a movie_id, Q returns the latent factor vector for that movie.\n",
    "        Q = Sequential()\n",
    "        Q.add(Embedding(m_items, k_factors, input_length=1))\n",
    "        Q.add(Reshape((k_factors,)))\n",
    "\n",
    "        super(CFModel, self).__init__(**kwargs)\n",
    "        \n",
    "        # The Merge layer takes the dot product of user and movie latent factor vectors to return the corresponding rating.\n",
    "        self.dot([P, Q], axes=1)\n",
    "        \n",
    "\n",
    "    # The rate function to predict user's rating of unrated items\n",
    "    def rate(self, user_id, item_id):\n",
    "        return self.predict([np.array([user_id]), np.array([item_id])])[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (((), ()), ()), types: ((tf.int64, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
